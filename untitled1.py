# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DbG1FOzOUd5IUyxsuDkwJp4In6WoCWES

# What is Image Classification?

* **The classification problem is to categorize all the pixels of a digital image into one of the defined classes.**
* Image classification is the most critical use case in digital image analysis.
* Image classification is an application of both supervised classification and unsupervised classification.
* In supervised classification, we select samples for each target class. We train our neural network on these target class samples and then classify new samples.
* In unsupervised classification, we group the sample images into clusters of images having similar properties. Then, we classify each cluster into our intended classes.

## About Image Classification Dataset

**CIFAR-10 is a very popular computer vision dataset. This dataset is well studied in many types of deep learning research for object recognition.**

This dataset consists of 60,000 images divided into 10 target classes, with each category containing 6000 images of shape 32*32. This dataset contains images of low resolution (32*32), which allows researchers to try new algorithms. The 10 different classes of this dataset are:

Airplane
Car
Bird
Cat
Deer
Dog
Frog
Horse
Ship
Truck

CIFAR-10 dataset is already available in the datasets module of Keras. We do not need to download it; we can directly import it from keras.datasets.

#### 1. Load the dataset from keras datasets module
"""

import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras import  models,layers,datasets
(train_X,train_Y),(test_X,test_Y)=tf.keras.datasets.cifar10.load_data()

"""#### 2. Plot some images from the dataset to visualize the dataset"""

n=6
plt.figure(figsize=(20,10))
for i in range(n):
  plt.subplot(330+1+i)
  plt.imshow(train_X[i])
plt.show()

"""#### 3. Import the required layers and modules to create our convolution neural net architecture"""

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import Flatten
from keras.constraints import maxnorm
from tensorflow.keras.optimizers import SGD
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.utils import np_utils

"""#### 4. Convert the pixel values of the dataset to float type and then normalize the dataset"""

train_X=train_X.astype('float32')
test_X=test_X.astype('float32')
 
train_X=train_X/255.0
test_X=test_X/255.0

train_Y

"""#### 5. Now perform the one-hot encoding for target classes"""

train_Y=np_utils.to_categorical(train_Y)
test_Y=np_utils.to_categorical(test_Y)
 
num_classes=test_Y.shape[1]

train_Y

test_Y.shape

"""#### 6. Create the sequential model and add the layers"""

model=Sequential()
model.add(Conv2D(32,(3,3),input_shape=(32,32,3),
    padding='same',activation='relu',
    kernel_constraint=maxnorm(3)))
model.add(Dropout(0.2))
model.add(Conv2D(32,(3,3),activation='relu',padding='same',kernel_constraint=maxnorm(3)))
model.add(MaxPooling2D(pool_size=(2,2)))
model.add(Flatten())
model.add(Dense(512,activation='relu',kernel_constraint=maxnorm(3)))
model.add(Dropout(0.5))
model.add(Dense(num_classes, activation='softmax'))

"""#### 7. Configure the optimizer and compile the model"""

sgd=SGD(learning_rate=0.01,momentum=0.9,decay=(0.01/25),nesterov=False)
 
model.compile(loss='categorical_crossentropy',
  optimizer=sgd,
  metrics=['accuracy'])

"""#### 8. View the model summary for better understanding of model architecture"""

model.summary()

model.fit(train_X,train_Y,
    validation_data=(test_X,test_Y),
    epochs=10,batch_size=32)

"""#### 10. Calculate it's accuracy on testing Data"""

acc=model.evaluate(test_X,test_Y)
print(acc*100)

model.save("model1_cifar_10epoch.h5")

results={
   0:'aeroplane',
   1:'automobile',
   2:'bird',
   3:'cat',
   4:'deer',
   5:'dog',
   6:'frog',
   7:'horse',
   8:'ship',
   9:'truck'
}
from PIL import Image
import numpy as np
im=Image.open("__image_path__")
# the input image is required to be in the shape of dataset, i.e (32,32,3)
 
im=im.resize((32,32))
im=np.expand_dims(im,axis=0)
im=np.array(im)
pred=model.predict_classes([im])[0]
print(pred,results[pred])

